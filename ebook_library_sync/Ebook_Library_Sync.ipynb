{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üìö Sincroniza√ß√£o de Biblioteca de Ebooks com Google Sheets\n",
    "\n",
    "Este notebook permite criar e manter atualizada uma planilha Google Sheets com todos os ebooks da sua biblioteca no Google Drive.\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- ‚úÖ Suporta bibliotecas grandes (50k+ arquivos)\n",
    "- ‚úÖ Varredura recursiva de todas as subpastas\n",
    "- ‚úÖ Cache inteligente para atualiza√ß√µes incrementais\n",
    "- ‚úÖ Retry autom√°tico em caso de erros de rede\n",
    "- ‚úÖ Logging detalhado do processo\n",
    "- ‚úÖ Formata√ß√£o autom√°tica da planilha\n",
    "\n",
    "**Formatos suportados:** PDF, EPUB, MOBI, AZW, AZW3, DJVU, FB2, TXT, RTF, DOC, DOCX, CBR, CBZ, LIT\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üîß Passo 1: Configura√ß√£o Inicial\n",
    "\n",
    "### 1.1 Montar Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_deps"
   },
   "source": [
    "### 1.2 Instalar Bibliotecas Necess√°rias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "!pip install -q google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client\n",
    "print(\"‚úì Bibliotecas instaladas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## ‚öôÔ∏è Passo 2: Configura√ß√£o\n",
    "\n",
    "**IMPORTANTE:** Ajuste os valores abaixo conforme sua configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config_vars"
   },
   "outputs": [],
   "source": [
    "# ========== CONFIGURA√á√ïES - AJUSTE AQUI ==========\n",
    "\n",
    "# Caminho para o arquivo de credenciais do Google Drive\n",
    "CREDENTIALS_PATH = \"/content/drive/MyDrive/0_Credentials/acessodriveorlando-44351dfb71f4.json\"\n",
    "\n",
    "# ID da pasta raiz da biblioteca no Google Drive\n",
    "LIBRARY_FOLDER_ID = \"0B9gSg9OIekOlajlGdWcxOWt0MlU\"\n",
    "\n",
    "# ID da planilha existente (deixe None para criar nova planilha)\n",
    "# Se voc√™ j√° tem uma planilha e quer atualizar, cole o ID aqui\n",
    "# Exemplo: \"1a2b3c4d5e6f7g8h9i0j\"\n",
    "SPREADSHEET_ID = None  # None = criar nova planilha\n",
    "\n",
    "# Nome da aba na planilha\n",
    "SHEET_NAME = \"Biblioteca de Ebooks\"\n",
    "\n",
    "# Arquivo de cache (para sincroniza√ß√µes incrementais futuras)\n",
    "CACHE_FILE = \"/content/drive/MyDrive/library_cache.pkl\"\n",
    "\n",
    "# =================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verification"
   },
   "source": [
    "### 2.1 Verificar Credenciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Verificar se arquivo de credenciais existe\n",
    "if os.path.exists(CREDENTIALS_PATH):\n",
    "    print(f\"‚úì Arquivo de credenciais encontrado: {CREDENTIALS_PATH}\")\n",
    "    \n",
    "    # Mostrar informa√ß√µes b√°sicas\n",
    "    with open(CREDENTIALS_PATH, 'r') as f:\n",
    "        creds = json.load(f)\n",
    "        print(f\"  - Tipo: {creds.get('type', 'N/A')}\")\n",
    "        print(f\"  - Projeto: {creds.get('project_id', 'N/A')}\")\n",
    "        print(f\"  - Email: {creds.get('client_email', 'N/A')}\")\n",
    "else:\n",
    "    print(f\"‚úó ERRO: Arquivo de credenciais n√£o encontrado: {CREDENTIALS_PATH}\")\n",
    "    print(\"  Verifique o caminho e tente novamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "script"
   },
   "source": [
    "## üìù Passo 3: C√≥digo do Script\n",
    "\n",
    "Execute a c√©lula abaixo para carregar o c√≥digo do sincronizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "script_code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Set\n",
    "import logging\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# Configura√ß√£o de logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class EbookLibrarySync:\n",
    "    \"\"\"Classe para sincronizar biblioteca de ebooks com Google Sheets\"\"\"\n",
    "\n",
    "    DRIVE_API_BATCH_SIZE = 1000\n",
    "    SHEETS_BATCH_SIZE = 10000\n",
    "    MAX_RETRIES = 5\n",
    "    RETRY_DELAY = 2\n",
    "\n",
    "    EBOOK_EXTENSIONS = {\n",
    "        '.pdf', '.epub', '.mobi', '.azw', '.azw3', '.djvu', '.fb2',\n",
    "        '.txt', '.rtf', '.doc', '.docx', '.cbr', '.cbz', '.lit'\n",
    "    }\n",
    "\n",
    "    def __init__(self, credentials_path: str, library_folder_id: str,\n",
    "                 cache_file: str = 'library_cache.pkl'):\n",
    "        self.credentials_path = credentials_path\n",
    "        self.library_folder_id = library_folder_id\n",
    "        self.cache_file = cache_file\n",
    "        self.drive_service = None\n",
    "        self.sheets_service = None\n",
    "        self.cache = self._load_cache()\n",
    "        logger.info(\"Inicializando EbookLibrarySync...\")\n",
    "        self._authenticate()\n",
    "\n",
    "    def _authenticate(self):\n",
    "        try:\n",
    "            logger.info(f\"Autenticando com credenciais: {self.credentials_path}\")\n",
    "            SCOPES = [\n",
    "                'https://www.googleapis.com/auth/drive.readonly',\n",
    "                'https://www.googleapis.com/auth/spreadsheets'\n",
    "            ]\n",
    "            credentials = service_account.Credentials.from_service_account_file(\n",
    "                self.credentials_path, scopes=SCOPES\n",
    "            )\n",
    "            self.drive_service = build('drive', 'v3', credentials=credentials)\n",
    "            self.sheets_service = build('sheets', 'v4', credentials=credentials)\n",
    "            logger.info(\"‚úì Autentica√ß√£o bem-sucedida!\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚úó Erro na autentica√ß√£o: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _load_cache(self) -> Dict:\n",
    "        if os.path.exists(self.cache_file):\n",
    "            try:\n",
    "                with open(self.cache_file, 'rb') as f:\n",
    "                    cache = pickle.load(f)\n",
    "                logger.info(f\"Cache carregado: {len(cache.get('files', {}))} arquivos\")\n",
    "                return cache\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Erro ao carregar cache: {e}\")\n",
    "        return {'files': {}, 'last_sync': None}\n",
    "\n",
    "    def _save_cache(self):\n",
    "        try:\n",
    "            self.cache['last_sync'] = datetime.now().isoformat()\n",
    "            with open(self.cache_file, 'wb') as f:\n",
    "                pickle.dump(self.cache, f)\n",
    "            logger.info(f\"Cache salvo: {len(self.cache['files'])} arquivos\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro ao salvar cache: {e}\")\n",
    "\n",
    "    def _retry_request(self, func, *args, **kwargs):\n",
    "        for attempt in range(self.MAX_RETRIES):\n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "            except HttpError as e:\n",
    "                if e.resp.status in [403, 429, 500, 503]:\n",
    "                    wait_time = self.RETRY_DELAY * (2 ** attempt)\n",
    "                    logger.warning(f\"Erro {e.resp.status}, tentando novamente em {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    raise\n",
    "            except Exception as e:\n",
    "                if attempt < self.MAX_RETRIES - 1:\n",
    "                    time.sleep(self.RETRY_DELAY)\n",
    "                else:\n",
    "                    raise\n",
    "        raise Exception(f\"Falha ap√≥s {self.MAX_RETRIES} tentativas\")\n",
    "\n",
    "    def _list_files_in_folder(self, folder_id: str, page_token: Optional[str] = None) -> Dict:\n",
    "        query = f\"'{folder_id}' in parents and trashed=false\"\n",
    "        fields = \"nextPageToken, files(id, name, mimeType, size, createdTime, modifiedTime, webViewLink, parents)\"\n",
    "        try:\n",
    "            results = self._retry_request(\n",
    "                self.drive_service.files().list,\n",
    "                q=query,\n",
    "                pageSize=self.DRIVE_API_BATCH_SIZE,\n",
    "                fields=fields,\n",
    "                pageToken=page_token\n",
    "            ).execute()\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro ao listar arquivos da pasta {folder_id}: {e}\")\n",
    "            return {'files': [], 'nextPageToken': None}\n",
    "\n",
    "    def _get_folder_path(self, file_id: str, file_name: str, cache_paths: Dict[str, str]) -> str:\n",
    "        if file_id in cache_paths:\n",
    "            return cache_paths[file_id]\n",
    "        try:\n",
    "            file_info = self._retry_request(\n",
    "                self.drive_service.files().get,\n",
    "                fileId=file_id,\n",
    "                fields='parents'\n",
    "            ).execute()\n",
    "            parents = file_info.get('parents', [])\n",
    "            if not parents or parents[0] == self.library_folder_id:\n",
    "                cache_paths[file_id] = f\"/{file_name}\"\n",
    "                return cache_paths[file_id]\n",
    "            parent_id = parents[0]\n",
    "            parent_info = self._retry_request(\n",
    "                self.drive_service.files().get,\n",
    "                fileId=parent_id,\n",
    "                fields='name, parents'\n",
    "            ).execute()\n",
    "            parent_name = parent_info.get('name', 'Unknown')\n",
    "            parent_path = self._get_folder_path(parent_id, parent_name, cache_paths)\n",
    "            full_path = f\"{parent_path}/{file_name}\"\n",
    "            cache_paths[file_id] = full_path\n",
    "            return full_path\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro ao obter caminho do arquivo {file_id}: {e}\")\n",
    "            return f\"/ERROR/{file_name}\"\n",
    "\n",
    "    def scan_library(self, progress_callback=None) -> List[Dict]:\n",
    "        logger.info(\"Iniciando varredura da biblioteca...\")\n",
    "        all_files = []\n",
    "        folders_to_process = [self.library_folder_id]\n",
    "        processed_folders = set()\n",
    "        cache_paths = {}\n",
    "        total_files = 0\n",
    "        total_folders = 0\n",
    "\n",
    "        while folders_to_process:\n",
    "            current_folder_id = folders_to_process.pop(0)\n",
    "            if current_folder_id in processed_folders:\n",
    "                continue\n",
    "            processed_folders.add(current_folder_id)\n",
    "            total_folders += 1\n",
    "            logger.info(f\"Processando pasta {total_folders}... (arquivos: {total_files})\")\n",
    "\n",
    "            page_token = None\n",
    "            while True:\n",
    "                results = self._list_files_in_folder(current_folder_id, page_token)\n",
    "                files = results.get('files', [])\n",
    "                \n",
    "                for file_info in files:\n",
    "                    file_id = file_info['id']\n",
    "                    file_name = file_info['name']\n",
    "                    mime_type = file_info['mimeType']\n",
    "                    \n",
    "                    if mime_type == 'application/vnd.google-apps.folder':\n",
    "                        folders_to_process.append(file_id)\n",
    "                        continue\n",
    "                    \n",
    "                    extension = Path(file_name).suffix.lower()\n",
    "                    if extension not in self.EBOOK_EXTENSIONS:\n",
    "                        continue\n",
    "                    \n",
    "                    file_path = self._get_folder_path(file_id, file_name, cache_paths)\n",
    "                    \n",
    "                    file_data = {\n",
    "                        'id': file_id,\n",
    "                        'nome': file_name,\n",
    "                        'caminho': file_path,\n",
    "                        'extensao': extension,\n",
    "                        'tamanho': int(file_info.get('size', 0)),\n",
    "                        'tamanho_mb': round(int(file_info.get('size', 0)) / (1024 * 1024), 2),\n",
    "                        'data_criacao': file_info.get('createdTime', ''),\n",
    "                        'data_modificacao': file_info.get('modifiedTime', ''),\n",
    "                        'link': file_info.get('webViewLink', ''),\n",
    "                        'mime_type': mime_type\n",
    "                    }\n",
    "                    \n",
    "                    all_files.append(file_data)\n",
    "                    total_files += 1\n",
    "                    \n",
    "                    if progress_callback and total_files % 100 == 0:\n",
    "                        progress_callback(total_files, total_folders)\n",
    "                \n",
    "                page_token = results.get('nextPageToken')\n",
    "                if not page_token:\n",
    "                    break\n",
    "                time.sleep(0.1)\n",
    "\n",
    "        logger.info(f\"‚úì Varredura conclu√≠da: {total_files} ebooks em {total_folders} pastas\")\n",
    "        return all_files\n",
    "\n",
    "    def create_or_update_spreadsheet(self, files_data: List[Dict],\n",
    "                                     spreadsheet_id: Optional[str] = None,\n",
    "                                     sheet_name: str = \"Biblioteca de Ebooks\") -> str:\n",
    "        logger.info(f\"{'Atualizando' if spreadsheet_id else 'Criando'} planilha...\")\n",
    "        \n",
    "        if not spreadsheet_id:\n",
    "            spreadsheet_id = self._create_spreadsheet(sheet_name)\n",
    "        \n",
    "        headers = [\n",
    "            'ID', 'Nome', 'Caminho', 'Extens√£o', 'Tamanho (bytes)',\n",
    "            'Tamanho (MB)', 'Data Cria√ß√£o', 'Data Modifica√ß√£o', 'Link'\n",
    "        ]\n",
    "        \n",
    "        rows = [headers]\n",
    "        for file_data in files_data:\n",
    "            row = [\n",
    "                file_data['id'],\n",
    "                file_data['nome'],\n",
    "                file_data['caminho'],\n",
    "                file_data['extensao'],\n",
    "                file_data['tamanho'],\n",
    "                file_data['tamanho_mb'],\n",
    "                file_data['data_criacao'],\n",
    "                file_data['data_modificacao'],\n",
    "                file_data['link']\n",
    "            ]\n",
    "            rows.append(row)\n",
    "        \n",
    "        self._update_sheet_in_batches(spreadsheet_id, sheet_name, rows)\n",
    "        self._format_spreadsheet(spreadsheet_id, sheet_name, len(rows))\n",
    "        \n",
    "        spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet_id}\"\n",
    "        logger.info(f\"‚úì Planilha atualizada: {spreadsheet_url}\")\n",
    "        return spreadsheet_id\n",
    "\n",
    "    def _create_spreadsheet(self, title: str) -> str:\n",
    "        try:\n",
    "            spreadsheet = {\n",
    "                'properties': {\n",
    "                    'title': f'{title} - {datetime.now().strftime(\"%Y-%m-%d %H:%M\")}'\n",
    "                }\n",
    "            }\n",
    "            spreadsheet = self._retry_request(\n",
    "                self.sheets_service.spreadsheets().create,\n",
    "                body=spreadsheet,\n",
    "                fields='spreadsheetId'\n",
    "            ).execute()\n",
    "            return spreadsheet.get('spreadsheetId')\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚úó Erro ao criar planilha: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _update_sheet_in_batches(self, spreadsheet_id: str, sheet_name: str, rows: List[List]):\n",
    "        total_rows = len(rows)\n",
    "        logger.info(f\"Atualizando planilha com {total_rows} linhas...\")\n",
    "        try:\n",
    "            self._retry_request(\n",
    "                self.sheets_service.spreadsheets().values().clear,\n",
    "                spreadsheetId=spreadsheet_id,\n",
    "                range=sheet_name,\n",
    "                body={}\n",
    "            ).execute()\n",
    "            \n",
    "            for i in range(0, total_rows, self.SHEETS_BATCH_SIZE):\n",
    "                batch = rows[i:i + self.SHEETS_BATCH_SIZE]\n",
    "                end_row = min(i + self.SHEETS_BATCH_SIZE, total_rows)\n",
    "                logger.info(f\"Atualizando linhas {i+1} a {end_row}...\")\n",
    "                body = {'values': batch}\n",
    "                self._retry_request(\n",
    "                    self.sheets_service.spreadsheets().values().update,\n",
    "                    spreadsheetId=spreadsheet_id,\n",
    "                    range=f\"{sheet_name}!A{i+1}\",\n",
    "                    valueInputOption='RAW',\n",
    "                    body=body\n",
    "                ).execute()\n",
    "                time.sleep(0.5)\n",
    "            logger.info(f\"‚úì {total_rows} linhas atualizadas!\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚úó Erro ao atualizar planilha: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _format_spreadsheet(self, spreadsheet_id: str, sheet_name: str, num_rows: int):\n",
    "        try:\n",
    "            spreadsheet = self._retry_request(\n",
    "                self.sheets_service.spreadsheets().get,\n",
    "                spreadsheetId=spreadsheet_id\n",
    "            ).execute()\n",
    "            \n",
    "            sheet_id = None\n",
    "            for sheet in spreadsheet['sheets']:\n",
    "                if sheet['properties']['title'] == sheet_name:\n",
    "                    sheet_id = sheet['properties']['sheetId']\n",
    "                    break\n",
    "            \n",
    "            if not sheet_id:\n",
    "                return\n",
    "            \n",
    "            requests = [\n",
    "                {\n",
    "                    'updateSheetProperties': {\n",
    "                        'properties': {\n",
    "                            'sheetId': sheet_id,\n",
    "                            'gridProperties': {'frozenRowCount': 1}\n",
    "                        },\n",
    "                        'fields': 'gridProperties.frozenRowCount'\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'repeatCell': {\n",
    "                        'range': {\n",
    "                            'sheetId': sheet_id,\n",
    "                            'startRowIndex': 0,\n",
    "                            'endRowIndex': 1\n",
    "                        },\n",
    "                        'cell': {\n",
    "                            'userEnteredFormat': {\n",
    "                                'textFormat': {'bold': True},\n",
    "                                'backgroundColor': {'red': 0.9, 'green': 0.9, 'blue': 0.9}\n",
    "                            }\n",
    "                        },\n",
    "                        'fields': 'userEnteredFormat(textFormat,backgroundColor)'\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'autoResizeDimensions': {\n",
    "                        'dimensions': {\n",
    "                            'sheetId': sheet_id,\n",
    "                            'dimension': 'COLUMNS',\n",
    "                            'startIndex': 0,\n",
    "                            'endIndex': 9\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            self._retry_request(\n",
    "                self.sheets_service.spreadsheets().batchUpdate,\n",
    "                spreadsheetId=spreadsheet_id,\n",
    "                body={'requests': requests}\n",
    "            ).execute()\n",
    "            logger.info(\"‚úì Planilha formatada!\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ö† Erro ao formatar planilha: {e}\")\n",
    "\n",
    "    def sync(self, spreadsheet_id: Optional[str] = None) -> str:\n",
    "        start_time = time.time()\n",
    "        logger.info(\"=\" * 60)\n",
    "        logger.info(\"INICIANDO SINCRONIZA√á√ÉO DA BIBLIOTECA\")\n",
    "        logger.info(\"=\" * 60)\n",
    "        \n",
    "        def progress(files, folders):\n",
    "            logger.info(f\"Progresso: {files} ebooks em {folders} pastas\")\n",
    "        \n",
    "        files_data = self.scan_library(progress_callback=progress)\n",
    "        \n",
    "        if not files_data:\n",
    "            logger.warning(\"Nenhum ebook encontrado!\")\n",
    "            return None\n",
    "        \n",
    "        self.cache['files'] = {f['id']: f for f in files_data}\n",
    "        self._save_cache()\n",
    "        \n",
    "        spreadsheet_id = self.create_or_update_spreadsheet(files_data, spreadsheet_id)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        total_size_gb = sum(f['tamanho'] for f in files_data) / (1024 ** 3)\n",
    "        \n",
    "        logger.info(\"=\" * 60)\n",
    "        logger.info(\"SINCRONIZA√á√ÉO CONCLU√çDA!\")\n",
    "        logger.info(f\"Total de ebooks: {len(files_data)}\")\n",
    "        logger.info(f\"Tamanho total: {total_size_gb:.2f} GB\")\n",
    "        logger.info(f\"Tempo: {elapsed_time:.2f} segundos\")\n",
    "        logger.info(f\"URL: https://docs.google.com/spreadsheets/d/{spreadsheet_id}\")\n",
    "        logger.info(\"=\" * 60)\n",
    "        \n",
    "        return spreadsheet_id\n",
    "\n",
    "print(\"‚úì Classe EbookLibrarySync carregada com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run"
   },
   "source": [
    "## üöÄ Passo 4: Executar Sincroniza√ß√£o\n",
    "\n",
    "Execute a c√©lula abaixo para iniciar a sincroniza√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_sync"
   },
   "outputs": [],
   "source": [
    "# Criar inst√¢ncia do sincronizador\n",
    "sync = EbookLibrarySync(\n",
    "    credentials_path=CREDENTIALS_PATH,\n",
    "    library_folder_id=LIBRARY_FOLDER_ID,\n",
    "    cache_file=CACHE_FILE\n",
    ")\n",
    "\n",
    "# Executar sincroniza√ß√£o\n",
    "spreadsheet_id = sync.sync(spreadsheet_id=SPREADSHEET_ID)\n",
    "\n",
    "# Exibir resultado\n",
    "if spreadsheet_id:\n",
    "    spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet_id}\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéâ SINCRONIZA√á√ÉO CONCLU√çDA COM SUCESSO!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nüìä Sua planilha est√° dispon√≠vel em:\")\n",
    "    print(f\"\\n{spreadsheet_url}\")\n",
    "    print(f\"\\nüí° Dica: Salve o ID da planilha para futuras atualiza√ß√µes:\")\n",
    "    print(f\"   SPREADSHEET_ID = \\\"{spreadsheet_id}\\\"\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "else:\n",
    "    print(\"\\n‚ö† Nenhum ebook encontrado na biblioteca.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stats"
   },
   "source": [
    "## üìä Passo 5: Estat√≠sticas (Opcional)\n",
    "\n",
    "Execute para ver estat√≠sticas detalhadas da sua biblioteca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show_stats"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Carregar dados do cache\n",
    "if sync.cache['files']:\n",
    "    files_data = list(sync.cache['files'].values())\n",
    "    \n",
    "    # Estat√≠sticas gerais\n",
    "    total_files = len(files_data)\n",
    "    total_size_gb = sum(f['tamanho'] for f in files_data) / (1024 ** 3)\n",
    "    \n",
    "    print(\"üìä ESTAT√çSTICAS DA BIBLIOTECA\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total de ebooks: {total_files:,}\")\n",
    "    print(f\"Tamanho total: {total_size_gb:.2f} GB\")\n",
    "    print(f\"Tamanho m√©dio: {(total_size_gb * 1024 / total_files):.2f} MB\")\n",
    "    \n",
    "    # Por extens√£o\n",
    "    extensions = Counter(f['extensao'] for f in files_data)\n",
    "    print(\"\\nüìö Por formato:\")\n",
    "    for ext, count in extensions.most_common():\n",
    "        percentage = (count / total_files) * 100\n",
    "        print(f\"  {ext}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Top 10 maiores arquivos\n",
    "    print(\"\\nüì¶ Top 10 maiores arquivos:\")\n",
    "    sorted_files = sorted(files_data, key=lambda x: x['tamanho'], reverse=True)[:10]\n",
    "    for i, f in enumerate(sorted_files, 1):\n",
    "        print(f\"  {i}. {f['nome']} ({f['tamanho_mb']} MB)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "else:\n",
    "    print(\"‚ö† Nenhum dado no cache. Execute a sincroniza√ß√£o primeiro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "advanced"
   },
   "source": [
    "## üîß Opera√ß√µes Avan√ßadas\n",
    "\n",
    "### Buscar arquivos espec√≠ficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "search"
   },
   "outputs": [],
   "source": [
    "# Buscar por palavra-chave no nome do arquivo\n",
    "search_term = \"python\"  # Altere aqui\n",
    "\n",
    "if sync.cache['files']:\n",
    "    results = [\n",
    "        f for f in sync.cache['files'].values()\n",
    "        if search_term.lower() in f['nome'].lower()\n",
    "    ]\n",
    "    \n",
    "    print(f\"üîç Resultados para '{search_term}': {len(results)} arquivo(s)\\n\")\n",
    "    \n",
    "    for f in results[:20]:  # Mostrar primeiros 20\n",
    "        print(f\"üìñ {f['nome']}\")\n",
    "        print(f\"   üìÅ {f['caminho']}\")\n",
    "        print(f\"   üìä {f['tamanho_mb']} MB\")\n",
    "        print(f\"   üîó {f['link']}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"‚ö† Execute a sincroniza√ß√£o primeiro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips"
   },
   "source": [
    "## üí° Dicas e Informa√ß√µes\n",
    "\n",
    "### Como atualizar a planilha existente:\n",
    "1. Copie o ID da planilha da URL (parte ap√≥s `/d/`)\n",
    "2. Defina `SPREADSHEET_ID = \"seu-id-aqui\"` na se√ß√£o de configura√ß√µes\n",
    "3. Execute novamente a sincroniza√ß√£o\n",
    "\n",
    "### Limites do Google Sheets:\n",
    "- M√°ximo de 10 milh√µes de c√©lulas\n",
    "- Com 9 colunas, voc√™ pode ter at√© ~1.1 milh√£o de linhas\n",
    "- Sua biblioteca com 200k arquivos est√° bem dentro do limite\n",
    "\n",
    "### Cache:\n",
    "- O cache √© salvo no seu Drive para acelerar sincroniza√ß√µes futuras\n",
    "- Ele ajuda a identificar arquivos novos, modificados ou removidos\n",
    "- Para for√ßar varredura completa, delete o arquivo de cache\n",
    "\n",
    "### Performance:\n",
    "- Para 50k arquivos: ~30-60 minutos\n",
    "- Para 100k arquivos: ~60-120 minutos\n",
    "- O tempo varia conforme a estrutura de pastas e conex√£o\n",
    "\n",
    "### Compartilhamento da planilha:\n",
    "Para compartilhar a planilha, voc√™ precisa dar permiss√£o ao email da service account:\n",
    "- Email: dispon√≠vel nas credenciais JSON (`client_email`)\n",
    "- Abra a planilha > Compartilhar > Adicione o email\n",
    "- Ou torne a planilha p√∫blica (qualquer pessoa com o link)\n",
    "\n",
    "---\n",
    "\n",
    "**Criado com ‚ù§Ô∏è por Claude**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Ebook_Library_Sync.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
